<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Linear Models</title>
    <meta charset="utf-8" />
    <meta name="author" content="MTH365: Introduction to Data Science" />
    <meta name="date" content="2025-02-27" />
    <script src="libs/header-attrs-2.29/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/default-fonts.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Linear Models
]
.author[
### MTH365: Introduction to Data Science
]
.date[
### February 27, 2025
]

---




## Announcements

**Lab 4**

- Due Tonight at 11:59 pm in Blueline

**Lab 5**: work day in class next Thursday (March 6)

- Due Tuesday after Spring Break (March 18)

**Mini Project 2**

- Due Thursday after Spring Break (March 20)

---
## Language of Models

Sometimes we want to know whether any variables are related, thus we need to fit a statistical model.

- We will focus on linear models, but there are many other types of models too!

.pull-left[
![](linear-models_files/figure-html/unnamed-chunk-2-1.png)&lt;!-- --&gt;
].pull-right[
![](linear-models_files/figure-html/unnamed-chunk-3-1.png)&lt;!-- --&gt;

]


---
## Fit a model

Sometimes we want to know whether any variables are related, thus we need to fit a statistical model. 

__Statistical models__: 

There are two things we can do with fitting a model:
1. Interpretation 
2. Prediction

Sometimes we are only interested in one of them, sometimes both. They have slightly different approaches and may lead to different choice and explanation of the model.

---
## Fit a model

Today's lecture we focus on interpretation and your mini-project 3 focuses on prediction. General steps for fitting a model for interpretation: 

1. Look at your research question. Identify the response variable.
2. Look at your data. Which variables may be related to the response variables?
3. Fit the variables to a statistical model
4. Check the p-values to decide whether the variables are significant and interpret their meaning. 

---
## Benefits and Drawbacks of Models

- **Benefits**: Models can sometimes reveal patterns that are not evident in a graph of the data.
- **Drawbacks**: There is a real risk, however, that a model is imposing structure that is not really there on the scatter of data, just as people imagine animal shapes in the stars or in clouds. A skeptical approach is always warranted.

---

## Looking for the potential correlation

__Example__: Review our NYC flight data. Is there any variable related to the arrival delay? If yes, how?

Consider a random sample of 1000 flights from NYC to Chicago in 2013.



Below are the column names of the data. Suppose we want to focus on if the time of the flights (`hour`) is related to the arrival delay (`arr_delay`)?


``` r
colnames(Chicago1000)
```



```
##      [,1]             [,2]             [,3]       [,4]       
## [1,] "year"           "dep_delay"      "flight"   "distance" 
## [2,] "month"          "arr_time"       "tailnum"  "hour"     
## [3,] "day"            "sched_arr_time" "origin"   "minute"   
## [4,] "dep_time"       "arr_delay"      "dest"     "time_hour"
## [5,] "sched_dep_time" "carrier"        "air_time" ""
```
 
---
### Visualizing a Model

The next step is to use a model. A popular model we can use is a Linear Model.

A Linear Model is easy to visualize when looking at the relationship between two numerical variables


``` r
Chicago1000 %&gt;% 
  ggplot(aes(x = hour, y = arr_delay)) + 
  geom_point() + 
  geom_smooth(method = "lm")
```

&lt;img src="linear-models_files/figure-html/unnamed-chunk-7-1.png" style="display: block; margin: auto;" /&gt;


---
### Linear model

__Population Linear model__: The relation between the observation `\(Y\)` and independent variables `\(X_1,..., X_p\)` is formulated as 
`$$Y = \beta_0 + \beta_1X_1 + ... + \beta_pX_p + \epsilon$$`
- Y denotes the value of the response variable
- `\(\beta_0\)` denotes the population intercept 
- `\(\beta_1\)` denotes the population slope for the first predictor 
- `\(X_1\)` denotes the value of the first predictor for each observation
- `\(\epsilon\)` denotes the error

--

__Sample Linear model__: `$$Y = \hat{\beta_0} + \hat{\beta_1}X_1 + ... + \hat{\beta_p}X_p$$`

+ `\(\hat{\beta}\)` denotes an estimate of the predictors

---
### Vocabulary

- **Response variable**: Variable whose behavior or variation you are trying to understand (y-axis)
  - For a linear regression model, this must be numeric
- **Explanatory variables**: Other variables that you want to use to explain the variation in the response (x-axis)
  
  
---
### Linear Model: One Numerical Predictor


``` r
model = lm(arr_delay ~ hour, data = Chicago1000)
summary(model)
```

```
## 
## Call:
## lm(formula = arr_delay ~ hour, data = Chicago1000)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -69.14 -25.96 -10.22   8.21 389.28 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -19.5500     4.2317  -4.620 4.34e-06 ***
## hour          2.0384     0.3094   6.587 7.23e-11 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 46.13 on 998 degrees of freedom
## Multiple R-squared:  0.04167,	Adjusted R-squared:  0.04071 
## F-statistic: 43.39 on 1 and 998 DF,  p-value: 7.227e-11
```

---
### Linear Model: One Numerical Predictor

Linear Model:

`$$\hat{y} = -19.55 + 2.0384*hours$$`

**Coefficient Interpretation**: If the hour increases by one unit (one hour), then the arrival delay will increase by 2.0384 units (minute). 

**Significance of Variable:** Hypothesis Test

- `\(H_0: \hat{\beta}_1 = 0\)`
&lt;!-- - `\(H_0: \hat{\beta}_1 \neq 0\)` --&gt;

  + Since the p-value (7.23e-11) is smaller than 0.05, there is a "statistically significant" relationship between arrival delay and hour.
  + There is thus strong evidence to reject the null hypothesis
  
---
### Linear Model: One Categorical Predictor

**Example**: What about carrier? Do different carriers lead to different average arrival delay?

&lt;img src="linear-models_files/figure-html/unnamed-chunk-9-1.png" style="display: block; margin: auto;" /&gt;


+ Make sure `carrier` is being treated as a factor!


---
### Linear Model: One Categorical Predictor

When a categorical explanatory variable has many levels, they're encoded to **dummy variables**
  
  - For a categorical variable with `\(k\)` levels, we have `\(k-1\)` indicator variables (have a baseline)
  - Each coefficient of an indicator variable describes the expected difference between that level compared to the baseline level
  
  
| carrier        | AA           | B6  | MQ| UA | WN |
| ------------- |:----:| -----:|-----:|-----:|-----:|-----:|
| 9E | 0 | 0 | 0 |  0 | 0|
| AA | 1 | 0 | 0 |  0 | 0|
| B6 | 0 | 1 | 0 |  0 | 0|
| MQ | 0 | 0 | 1 |  0 | 0|
| UA | 0 | 0 | 0 |  1 | 0|
| WN | 0 | 0 | 0 |  0 | 1|

---
### Linear Model: One Categorical Predictor


``` r
Chicago1000$carrier = relevel(as.factor(Chicago1000$carrier), 
                              ref = "UA")

model3 = lm(arr_delay ~ carrier, data = Chicago1000)
broom::tidy(model3)
```

```
## # A tibble: 6 × 5
##   term        estimate std.error statistic p.value
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;
## 1 (Intercept)     4.86      2.59     1.88  0.0607 
## 2 carrier9E       4.35      6.33     0.688 0.492  
## 3 carrierAA     -10.7       3.76    -2.83  0.00468
## 4 carrierB6      20.8       7.58     2.74  0.00620
## 5 carrierMQ      12.7       5.30     2.40  0.0165 
## 6 carrierWN      12.6       4.24     2.98  0.00297
```

Carrier UA is the reference level and every other levels will be compared to it.

---
## Linear Model with Categorical Explanatory

Writing out the proper model:

`$$\hat{\text{y}} = 4.86+4.35*\text{9E}-10.7*\text{AA}+20.8*\text{B6}+12.7*\text{MQ}+12.6*\text{WN}$$`


For UA (Reference level):

`\(\hat{Y} = 4.86 + 4.25(0) - 10.7(0) + 20.8(0) + 12.7(0) + 12.6(0) =\)`

`\(\hat{Y} = 4.86\)`

--

For AA: 

--

`\(\hat{Y} = 4.86 + 4.25(0) - 10.7(1) + 20.8(0) + 12.7(0) + 12.6(0) =\)`

`\(\hat{Y} = -5.84\)`

---
## Linear Model with Categorical Explanatory

Interpreting p-value: 

+ P-Value for `carrierAA` = 0.00468
  - `\(H_0: \mu_{UA} = \mu_{AA}\)`
  - `\(H_A: \mu_{UA} \neq \mu_{AA}\)`
+ Meaning that we have evidence that UA and AA have significantly different departure delays.

All p-values are comparing each category to the reference level, which we generally don't care about.


---
### Analysis of Variance (ANOVA)

**Analysis of variance**: used to analyze the differences among means.


**Question**: Does at least one of the carriers have a different mean arrival delay than the others


``` r
model4 = aov(arr_delay ~ carrier, data = Chicago1000)
summary(model4)
```

```
##              Df  Sum Sq Mean Sq F value  Pr(&gt;F)    
## carrier       5   95301   19060   8.932 2.6e-08 ***
## Residuals   994 2121209    2134                    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

At least one of the carrier has different mean arrival delay than the others (p-value = 2.6e-08), thus carriers are significantly related to the arrival delay. 

---
### ANOVA: Multiple Comparisons

The ANOVA test itself provides only statistical evidence of a difference, but not any statistical evidence as to which mean or means are statistically different.

Multiple comparisons conducts an analysis of all possible pairwise means. 

An adjustment is needed to account for the number of comparisons taking place (we won't get into this). 
---
## Statistical signficance: Multiple Comparisons


``` r
library(multcomp)
model5 = glht(model4, linfct = mcp(carrier = "Tukey"))
summary(model5, test = adjusted("holm"))
```


```
## # A tibble: 15 × 7
##    term    contrast null.value estimate std.error statistic adj.p.value
##    &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;
##  1 carrier 9E - UA           0   4.35        6.33    0.688   1         
##  2 carrier AA - UA           0 -10.7         3.76   -2.83    0.0514    
##  3 carrier B6 - UA           0  20.8         7.58    2.74    0.0620    
##  4 carrier MQ - UA           0  12.7         5.30    2.40    0.149     
##  5 carrier WN - UA           0  12.6         4.24    2.98    0.0356    
##  6 carrier AA - 9E           0 -15.0         6.39   -2.35    0.151     
##  7 carrier B6 - 9E           0  16.4         9.17    1.79    0.513     
##  8 carrier MQ - 9E           0   8.36        7.39    1.13    1         
##  9 carrier WN - 9E           0   8.28        6.68    1.24    1         
## 10 carrier B6 - AA           0  31.5         7.63    4.12    0.000527  
## 11 carrier MQ - AA           0  23.4         5.36    4.36    0.000203  
## 12 carrier WN - AA           0  23.3         4.33    5.38    0.00000136
## 13 carrier MQ - B6           0  -8.09        8.49   -0.952   1         
## 14 carrier WN - B6           0  -8.16        7.88   -1.04    1         
## 15 carrier WN - MQ           0  -0.0774      5.71   -0.0135  1
```

---
## Confounding

**"Correlation does not equal causation."**

What variables could be used in a model to _explain_ arrival delays?

In other words, just because there is a "statistically significant relationship" between `\(x\)` and `\(y\)`, it doesn't mean that `\(x\)` is _causing_ changes in `\(y\)`.

Other factors may affect (*confound*) the relationship between two variables.

---
## Carrier as a confounder?

__Example__: Does carrier confound the relationship between arrival delay and hour?


``` r
Chicago1000 %&gt;% ggplot(aes(x = hour, y = arr_delay)) + 
  geom_point() + 
  geom_smooth(method = "lm") + 
  aes(color = carrier)
```

&lt;img src="linear-models_files/figure-html/unnamed-chunk-14-1.png" style="display: block; margin: auto;" /&gt;



---
## Multiple Linear Regression

**Until Now**: We've only had one predictor variable in our model. 

But if we suspect a variable may affect the relationship between another variable and the response (or we have multiple predictor variables of interest), we need a way to test their significance.
  - Overall F Test
  - Individual tests
  
---


``` r
model6 = lm(arr_delay ~ hour + carrier, data = Chicago1000)
summary(model6)
```

```
## 
## Call:
## lm(formula = arr_delay ~ hour + carrier, data = Chicago1000)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -64.26 -24.12 -10.68   8.32 390.10 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -19.4396     4.6483  -4.182 3.14e-05 ***
## hour          1.9055     0.3051   6.246 6.25e-10 ***
## carrier9E     2.8147     6.2161   0.453  0.65078    
## carrierAA    -9.9018     3.6933  -2.681  0.00746 ** 
## carrierB6    20.2891     7.4437   2.726  0.00653 ** 
## carrierMQ    11.9620     5.1993   2.301  0.02161 *  
## carrierWN    11.6865     4.1668   2.805  0.00513 ** 
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 45.34 on 993 degrees of freedom
## Multiple R-squared:  0.07917,	Adjusted R-squared:  0.07361 
## F-statistic: 14.23 on 6 and 993 DF,  p-value: 1.337e-15
```
  
---
## Overall F Test

Testing for significance of all predictor variables at once 
- Null: The slope for all of the predictor variables is 0
- Alternative: The slope for at least one of the predictor variables is not 0

Asking, is the regression model containing at least one of the predictors useful in predicting the response?

---
### Individual Significance Tests

Similar to model with one predictor variable, but p-value is calculated assuming all of the other variables are in the model.

- `\(H_0: \hat{\beta}_1 = 0 \text{; assuming carrier is included}\)`
- `\(H_0: \hat{\beta}_1 \neq 0 \text{; assuming carrier is included}\)`


Coefficients and p-values may change when variables are added and taken away. 

+ An increase in the hour of departure increases the arrival delay by 1.9 minutes, assuming carrier is held constant

---
### Variable Selection

Since the choice of variables affects the quality of the model, how do we know which to pick?

Measure the "quality" of the model in some way, and pick the variables which give you the highest quality.

Some measures of quality
- *Traditional Statistics:* Adjusted `\(R^2\)`
- *Information Theory*: Akaike information criterion (AIC)/Bayesian Information Criterion (BIC)
- *Hacks*: Prediction Accuracy (next class period)

**Note**: This is far from an exhaustive list

---
### Adjusted `\(R^2\)`

How much of the variation in our response is explained by the model

The Adjusted `\(R^2\)` does not automatically increase for additional variables
  - If a variable is not useful, Adjusted `\(R^2\)` will decrease 
  - Can use to help check variable importance
  

**Example**: 
- For our model with hour and carrier: 7.361% of the variation in arrival delay is explained by the model 
- For our model with hour only: 4.071% of the variation in arrival delay is explained by the model

---
### AIC and BIC

Other methods to determine what variables to include in your model (model comparison).

They may not always agree as to which is the best model, so generally people choose the model based on which one is best among the fit statistics most often.

--

Other: Common Fit Statistics

- AIC: penalize the inclusion of additional variables to a model. It adds a penalty that increases the error when including additional terms. 

``` r
AIC(model6)
```

```
## [1] 10475.09
```

- BIC: Stronger penalty for including additional variables to the model.


``` r
BIC(model6)
```

```
## [1] 10514.35
```


---
### Now we can create a linear model, but is it appropriate?

If you ask for a line of best fit, you're going to get a line, no matter what your data looks like.

1. We need to have a linear relationship
2. The response has a normal distribution (when adjusted for the regression)
3. Constant variance (when adjusted for the regression)
4. No perfect collinearity (i.e. one predictor isn’t a linear combination of other predictors in the model)
  - Focus on numerical predictor variables
5. Observations are independent
  
---
## Assumption: Normality

- If the response has a non-normal distribution, the estimates will be biased

To check this assumption, we use a QQ-Plot
  - A scatterplot created by plotting two sets of quantiles against one another.
  - If data is normal, we should see a roughly straight line
  

``` r
plot(model6, which = 2)
```

&lt;img src="linear-models_files/figure-html/unnamed-chunk-18-1.png" style="display: block; margin: auto;" /&gt;

---
## Assumption: Linearity

Look at the Residuals vs Fitted Plot
- Look to see if there are any noticeable pattern in any of the plots
- If pattern, linearity assumption is violated


``` r
plot(model6, which = 1)
```

&lt;img src="linear-models_files/figure-html/unnamed-chunk-19-1.png" style="display: block; margin: auto;" /&gt;

---
## Assumption: Constant Variance

- Looking for a constant spread of the residuals
- Don't want to see a narrowing or widening of points (fan shaped)


``` r
plot(model6, which = 3)
```

&lt;img src="linear-models_files/figure-html/unnamed-chunk-20-1.png" style="display: block; margin: auto;" /&gt;

---
## Assumption: No Perfect Collinearity

Collinearity - a linear relationship between two variables
  - one predictor is a linear combination of other predictors in the model
  - Example: can't include `revenue`, `profit`, `cost` as `profit = revenue - cost`


High correlation between predictor variables
  - Standard errors become inflated, which can lead to `\(\hat{\beta}\)` having the wrong sign in our predictors
  - We interpret 1 variable while holding all others constant. Holding the others constant may not be possible
  
When is this an issue:
- Generally, the absolute value of a correlation between predictors above 0.8 is considered serious (caution is typically advised once you hit around 0.6)


---
## Assumption: No Perfect Collinearity

Let's look at the relationship between `air_time` and `distance`


``` r
library(corrplot)
```

```
## corrplot 0.95 loaded
```

``` r
M &lt;- cor(Chicago1000[,c(15:16)])
corrplot(M, method = "number", type = "upper")
```

&lt;img src="linear-models_files/figure-html/unnamed-chunk-21-1.png" style="display: block; margin: auto;" /&gt;


---
### Last Thing

- Non-constant variance is one of the most common model violations, however it is usually fixable by transforming the response (y) variable.
  + Common transformation is the log-transformation or square root
  + Be careful with your interpretations (untransform your response variable)


- If you notice a curve in your data, you can add a quadratic term
  + `\(\hat{Y} = \hat{\beta_0} + \hat{\beta_1}X_1 + \hat{\beta_2}X_1^2\)`
  + `lm(arr_delay ~ hour + I(hour^2), data = Chicago1000)`


- Interactions: used if you think two variables are related to each other
  + Allows for different slopes (coefficient for an explanatory variable would change as another explanatory variable changes)
    + `\(\hat{Y} = \hat{\beta_0} + \hat{\beta_1}X_1 + \hat{\beta_2}X_2 + \hat{\beta_3}X_1X_2\)`
  + `int = lm(arr_delay ~ hour + carrier + hour:carrier, data = Chicago1000)`
  
---
## Your Turn!

Choose some other explanatory variables and try them out! Can you find a good possible model for predicting arrival delay?


    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
