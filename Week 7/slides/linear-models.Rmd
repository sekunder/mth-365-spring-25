---
author: "MTH365: Introduction to Data Science"
title: "Linear Models"
date: "February 27, 2025"
output: 
  xaringan::moon_reader:
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r echo=FALSE, message=FALSE, warning = FALSE}
library(tidyverse)
library(knitr)
library(RColorBrewer)
library(mosaic)


hook_output = knit_hooks$get('output')
knit_hooks$set(output = function(x, options) {
  # this hook is used only when the linewidth option is not NULL
  if (!is.null(n <- options$linewidth)) {
    x = xfun::split_lines(x)
    # any lines wider than n should be wrapped
    if (any(nchar(x) > n)) x = strwrap(x, width = n)
    x = paste(x, collapse = '\n')
  }
  hook_output(x, options)
})

```

## Announcements

**Lab 4**

- Due Tonight at 11:59 pm in Blueline

**Lab 5**: work day in class next Thursday (March 6)

- Due Tuesday after Spring Break (March 18)

**Mini Project 2**

- Due Thursday after Spring Break (March 20)

---
## Language of Models

Sometimes we want to know whether any variables are related, thus we need to fit a statistical model.

- We will focus on linear models, but there are many other types of models too!

.pull-left[
```{r, message=FALSE, echo = FALSE}
x = seq(-100, 100)    # just a sequence of numbers
y = x + rnorm(length(x), 0, 50)      # generate linear association + noise

xy <- data.frame(x,y)

xy %>% ggplot(aes(x=x, y = y)) + geom_point() +
  geom_smooth(method = "lm", color = "orange", se = FALSE) +
  ggtitle("Linear Relationship")
```
].pull-right[
```{r, message=FALSE, echo = FALSE}
x = seq(-100, 100)    # just a sequence of numbers
y = x^2 + rnorm(length(x), 0, 1000)      # generate non-linear association + noise

xy <- data.frame(x,y)

xy %>% ggplot(aes(x=x, y = y)) + geom_point() +
  geom_smooth(method = "loess", color = "purple", se = FALSE) +
  geom_smooth(method = "lm", color = "orange", se = FALSE) +
  ggtitle("Non-Linear Relationship")
```

]


---
## Fit a model

Sometimes we want to know whether any variables are related, thus we need to fit a statistical model. 

__Statistical models__: 

There are two things we can do with fitting a model:
1. Interpretation 
2. Prediction

Sometimes we are only interested in one of them, sometimes both. They have slightly different approaches and may lead to different choice and explanation of the model.

---
## Fit a model

Today's lecture we focus on interpretation and your mini-project 3 focuses on prediction. General steps for fitting a model for interpretation: 

1. Look at your research question. Identify the response variable.
2. Look at your data. Which variables may be related to the response variables?
3. Fit the variables to a statistical model
4. Check the p-values to decide whether the variables are significant and interpret their meaning. 

---
## Benefits and Drawbacks of Models

- **Benefits**: Models can sometimes reveal patterns that are not evident in a graph of the data.
- **Drawbacks**: There is a real risk, however, that a model is imposing structure that is not really there on the scatter of data, just as people imagine animal shapes in the stars or in clouds. A skeptical approach is always warranted.

---

## Looking for the potential correlation

__Example__: Review our NYC flight data. Is there any variable related to the arrival delay? If yes, how?

Consider a random sample of 1000 flights from NYC to Chicago in 2013.

```{r, echo = FALSE}
library(nycflights13)
set.seed(14)
Chicago1000 <- flights %>%
  filter(dest %in% c('ORD', 'MDW'), !is.na(arr_delay)) %>% 
  sample_n(size=1000)
```

Below are the column names of the data. Suppose we want to focus on if the time of the flights (`hour`) is related to the arrival delay (`arr_delay`)?

```{r eval = FALSE}
colnames(Chicago1000)
```


```{r, echo=FALSE}
matrix(c(colnames(Chicago1000), ""), nrow = 5, ncol = 4) 
```
 
---
### Visualizing a Model

The next step is to use a model. A popular model we can use is a Linear Model.

A Linear Model is easy to visualize when looking at the relationship between two numerical variables

```{r, message=FALSE, fig.align='center', fig.height=3.5, fig.width=8}
Chicago1000 %>% 
  ggplot(aes(x = hour, y = arr_delay)) + 
  geom_point() + 
  geom_smooth(method = "lm")
```


---
### Linear model

__Population Linear model__: The relation between the observation $Y$ and independent variables $X_1,..., X_p$ is formulated as 
$$Y = \beta_0 + \beta_1X_1 + ... + \beta_pX_p + \epsilon$$
- Y denotes the value of the response variable
- $\beta_0$ denotes the population intercept 
- $\beta_1$ denotes the population slope for the first predictor 
- $X_1$ denotes the value of the first predictor for each observation
- $\epsilon$ denotes the error

--

__Sample Linear model__: $$Y = \hat{\beta_0} + \hat{\beta_1}X_1 + ... + \hat{\beta_p}X_p$$

+ $\hat{\beta}$ denotes an estimate of the predictors

---
### Vocabulary

- **Response variable**: Variable whose behavior or variation you are trying to understand (y-axis)
  - For a linear regression model, this must be numeric
- **Explanatory variables**: Other variables that you want to use to explain the variation in the response (x-axis)
  
  
---
### Linear Model: One Numerical Predictor

```{r}
model = lm(arr_delay ~ hour, data = Chicago1000)
summary(model)
```

---
### Linear Model: One Numerical Predictor

Linear Model:

$$\hat{y} = -19.55 + 2.0384*hours$$

**Coefficient Interpretation**: If the hour increases by one unit (one hour), then the arrival delay will increase by 2.0384 units (minute). 

**Significance of Variable:** Hypothesis Test

- $H_0: \hat{\beta}_1 = 0$
<!-- - $H_0: \hat{\beta}_1 \neq 0$ -->

  + Since the p-value (7.23e-11) is smaller than 0.05, there is a "statistically significant" relationship between arrival delay and hour.
  + There is thus strong evidence to reject the null hypothesis
  
---
### Linear Model: One Categorical Predictor

**Example**: What about carrier? Do different carriers lead to different average arrival delay?

```{r, message=FALSE, warning=FALSE, echo=FALSE, fig.align='center', fig.height=5, fig.width=8}
Chicago1000 %>% 
  ggplot(aes(x = carrier, y = arr_delay)) + 
  geom_boxplot(aes(color = carrier))
```


+ Make sure `carrier` is being treated as a factor!


---
### Linear Model: One Categorical Predictor

When a categorical explanatory variable has many levels, they're encoded to **dummy variables**
  
  - For a categorical variable with $k$ levels, we have $k-1$ indicator variables (have a baseline)
  - Each coefficient of an indicator variable describes the expected difference between that level compared to the baseline level
  
  
| carrier        | AA           | B6  | MQ| UA | WN |
| ------------- |:----:| -----:|-----:|-----:|-----:|-----:|
| 9E | 0 | 0 | 0 |  0 | 0|
| AA | 1 | 0 | 0 |  0 | 0|
| B6 | 0 | 1 | 0 |  0 | 0|
| MQ | 0 | 0 | 1 |  0 | 0|
| UA | 0 | 0 | 0 |  1 | 0|
| WN | 0 | 0 | 0 |  0 | 1|

---
### Linear Model: One Categorical Predictor

```{r}
Chicago1000$carrier = relevel(as.factor(Chicago1000$carrier), 
                              ref = "UA")

model3 = lm(arr_delay ~ carrier, data = Chicago1000)
broom::tidy(model3)
```

Carrier UA is the reference level and every other levels will be compared to it.

---
## Linear Model with Categorical Explanatory

Writing out the proper model:

$$\hat{\text{y}} = 4.86+4.35*\text{9E}-10.7*\text{AA}+20.8*\text{B6}+12.7*\text{MQ}+12.6*\text{WN}$$


For UA (Reference level):

$\hat{Y} = 4.86 + 4.25(0) - 10.7(0) + 20.8(0) + 12.7(0) + 12.6(0) =$

$\hat{Y} = 4.86$

--

For AA: 

--

$\hat{Y} = 4.86 + 4.25(0) - 10.7(1) + 20.8(0) + 12.7(0) + 12.6(0) =$

$\hat{Y} = -5.84$

---
## Linear Model with Categorical Explanatory

Interpreting p-value: 

+ P-Value for `carrierAA` = 0.00468
  - $H_0: \mu_{UA} = \mu_{AA}$
  - $H_A: \mu_{UA} \neq \mu_{AA}$
+ Meaning that we have evidence that UA and AA have significantly different departure delays.

All p-values are comparing each category to the reference level, which we generally don't care about.


---
### Analysis of Variance (ANOVA)

**Analysis of variance**: used to analyze the differences among means.


**Question**: Does at least one of the carriers have a different mean arrival delay than the others

```{r}
model4 = aov(arr_delay ~ carrier, data = Chicago1000)
summary(model4)
```

At least one of the carrier has different mean arrival delay than the others (p-value = 2.6e-08), thus carriers are significantly related to the arrival delay. 

---
### ANOVA: Multiple Comparisons

The ANOVA test itself provides only statistical evidence of a difference, but not any statistical evidence as to which mean or means are statistically different.

Multiple comparisons conducts an analysis of all possible pairwise means. 

An adjustment is needed to account for the number of comparisons taking place (we won't get into this). 
---
## Statistical signficance: Multiple Comparisons

```{r, eval=FALSE, message = FALSE}
library(multcomp)
model5 = glht(model4, linfct = mcp(carrier = "Tukey"))
summary(model5, test = adjusted("holm"))
```

```{r, echo=FALSE, message = FALSE}
library(multcomp)
model5 = glht(model4, linfct = mcp(carrier = "Tukey"))
s <- summary(model5, test = adjusted("holm"))
broom::tidy(s)
```

---
## Confounding

**"Correlation does not equal causation."**

What variables could be used in a model to _explain_ arrival delays?

In other words, just because there is a "statistically significant relationship" between $x$ and $y$, it doesn't mean that $x$ is _causing_ changes in $y$.

Other factors may affect (*confound*) the relationship between two variables.

---
## Carrier as a confounder?

__Example__: Does carrier confound the relationship between arrival delay and hour?

```{r, message=FALSE, fig.align='center', fig.height=4, fig.width=8}
Chicago1000 %>% ggplot(aes(x = hour, y = arr_delay)) + 
  geom_point() + 
  geom_smooth(method = "lm") + 
  aes(color = carrier)
```



---
## Multiple Linear Regression

**Until Now**: We've only had one predictor variable in our model. 

But if we suspect a variable may affect the relationship between another variable and the response (or we have multiple predictor variables of interest), we need a way to test their significance.
  - Overall F Test
  - Individual tests
  
---

```{r}
model6 = lm(arr_delay ~ hour + carrier, data = Chicago1000)
summary(model6)
```
  
---
## Overall F Test

Testing for significance of all predictor variables at once 
- Null: The slope for all of the predictor variables is 0
- Alternative: The slope for at least one of the predictor variables is not 0

Asking, is the regression model containing at least one of the predictors useful in predicting the response?

---
### Individual Significance Tests

Similar to model with one predictor variable, but p-value is calculated assuming all of the other variables are in the model.

- $H_0: \hat{\beta}_1 = 0 \text{; assuming carrier is included}$
- $H_0: \hat{\beta}_1 \neq 0 \text{; assuming carrier is included}$


Coefficients and p-values may change when variables are added and taken away. 

+ An increase in the hour of departure increases the arrival delay by 1.9 minutes, assuming carrier is held constant

---
### Variable Selection

- Adjusted $R^2$
- AIC/BIC
- Prediction Accuracy (next class period)

**Note**: This is far from an exhaustive list

---
### Adjusted $R^2$

How much of the variation in our response is explained by the model

The Adjusted $R^2$ does not automatically increase for additional variables
  - If a variable is not useful, Adjusted $R^2$ will decrease 
  - Can use to help check variable importance
  

**Example**: 
- For our model with hour and carrier: 7.361% of the variation in arrival delay is explained by the model 
- For our model with hour only: 4.071% of the variation in arrival delay is explained by the model

---
### AIC and BIC

Other methods to determine what variables to include in your model (model comparison).

They may not always agree as to which is the best model, so generally people choose the model based on which one is best among the fit statistics most often.

--

Other: Common Fit Statistics

- AIC: penalize the inclusion of additional variables to a model. It adds a penalty that increases the error when including additional terms. 
```{r}
AIC(model6)
```

- BIC: Stronger penalty for including additional variables to the model.

```{r}
BIC(model6)
```


---
### Now we can create a linear model, but is it appropriate?

1. The response has a normal distribution
2. We need to have a linear relationship
3. Constant variance
4. No perfect collinearity (i.e. one predictor isn’t a linear combination of other predictors in the model)
  - Focus on numerical predictor variables
5. Observations are independent
  
---
## Assumption: Normality

- If the response has a non-normal distribution, the estimates will be biased

To check this assumption, we use a QQ-Plot
  - A scatterplot created by plotting two sets of quantiles against one another.
  - If data is normal, we should see a roughly straight line
  
```{r, fig.align='center', fig.height=3.5, fig.width=8}
plot(model6, which = 2)
```

---
## Assumption: Linearity

Look at the Residuals vs Fitted Plot
- Look to see if there are any noticeable pattern in any of the plots
- If pattern, linearity assumption is violated

```{r, fig.align='center', fig.height=5, fig.width=8}
plot(model6, which = 1)
```

---
## Assumption: Constant Variance

- Looking for a constant spread of the residuals
- Don't want to see a narrowing or widening of points (fan shaped)

```{r, fig.align='center', fig.height=5, fig.width=8}
plot(model6, which = 3)
```

---
## Assumption: No Perfect Collinearity

Collinearity - a linear relationship between two variables
  - one predictor is a linear combination of other predictors in the model
  - Example: can't include `revenue`, `profit`, `cost` as `profit = revenue - cost`


High correlation between predictor variables
  - Standard errors become inflated, which can lead to $\hat{\beta}$ having the wrong sign in our predictors
  - We interpret 1 variable while holding all others constant. Holding the others constant may not be possible
  
When is this an issue:
- Generally, the absolute value of a correlation above 0.8 is considered serious (caution is typically advised once you hit around 0.6)


---
## Assumption: No Perfect Collinearity

Let's look at the relationship between `air_time` and `distance`

```{r, fig.align='center', fig.height=5, fig.width=8}
library(corrplot)
M <- cor(Chicago1000[,c(15:16)])
corrplot(M, method = "number", type = "upper")
```


---
### Last Thing

- Non-constant variance is one of the most common model violations, however it is usually fixable by transforming the response (y) variable.
  + Common transformation is the log-transformation or square root
  + Be careful with your interpretations (untransform your response variable)
- If you notice a curve in your data, you can add a quadratic term
  + $\hat{Y} = \hat{\beta_0} + \hat{\beta_1}X_1 + \hat{\beta_2}X_1^2$
  + `lm(arr_delay ~ hour + I(hour^2), data = Chicago1000)`
- Interactions: used if you think two variables are related to each other
  + Allows for different slopes (coefficient for an explanatory variable would change as another explanatory variable changes)
    + $\hat{Y} = \hat{\beta_0} + \hat{\beta_1}X_1 + \hat{\beta_2}X_2 + \hat{\beta_3}X_1X_2$
  + `int = lm(arr_delay ~ hour + carrier + hour:carrier, data = Chicago1000)`
  
---
## Your Turn!

Choose some other explanatory variables and try them out! Can you find a good possible model for predicting arrival delay?


