<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>KNN (k Nearest Neighbors)</title>
    <meta charset="utf-8" />
    <meta name="author" content="MTH365: Introduction to Data Science" />
    <meta name="date" content="2025-03-25" />
    <script src="libs/header-attrs-2.29/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/default-fonts.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# KNN (k Nearest Neighbors)
]
.author[
### MTH365: Introduction to Data Science
]
.date[
### March 25, 2025
]

---




&lt;style type="text/css"&gt;
.tiny .remark-code { /*Change made here*/
  font-size: 70% !important;
}
&lt;/style&gt;


## Announcements

**Mini Project 2** You tried to warn me... please upload to the assignment labeled "UPLOAD HERE" and not the one labeled "NOT HERE" (I changed the assignment names last night)

**Lab 6**: Due tonight at in Blueline

**Mini Project 3**

- Details on Thursday

**Lab 7**: work day in class on Thursday

- Due next Tuesday


---
## "Lazy" learning

So far we've focused on building models that can predict outcomes on a new set of data. Another approach is to just be _lazy_!

__Lazy learning__: no assumptions necessary to classify data

- How does that work?

__Example__: Consider the plot below - describe the relationship between x and y.

&lt;img src="knn-and-classification_files/figure-html/unnamed-chunk-3-1.png" style="display: block; margin: auto;" /&gt;

---
## "Lazy" learning

What if the data points belonged to three different groups, like this?

&lt;img src="knn-and-classification_files/figure-html/unnamed-chunk-4-1.png" style="display: block; margin: auto;" /&gt;

---
## "Lazy" learning

How should a new data point, `\((0.2, 0.5)\)` be classified? What about `\((0.4, 0.2)\)`?

&lt;img src="knn-and-classification_files/figure-html/unnamed-chunk-5-1.png" style="display: block; margin: auto;" /&gt;

---
## Bayes Classifier

A good classifier minimizes Testing Error, the probability of mis-classifying an input

Bayes Classifier assigns each observation `\(x_0\)` to is most likely class using:

`$$f(j) = \arg\max_j P(Y = j|X = x_0)$$`
+ Bayes Classifier produce the lowest possible test error rate [(proof)](https://www.ee.columbia.edu/~vittorio/BayesProof.pdf)

**Problem**: Don't know the conditional distribution (if we did, we wouldn't need a classifier...)

---
## `\(k\)`-nearest neighbor (`\(k\)`-NN or KNN) classifier: 


A non-parametric supervised learning method that estimates the conditional probability.

- In `\(k\)`-NN classification, the output is a class membership. An object is classified by a plurality vote of its neighbors, with the object being assigned to the class most common among its `\(k\)` nearest neighbors (`\(k\)` is a positive integer). 



---
## KNN for Classification Steps

In the KNN algorithm, `\(k\)` specifies the number of neighbors and its algorithm to classify a new input `\(x\)` is as follows:

&lt;!-- - Choose the number `\(k\)` of neighbors --&gt;
- Find the `\(k\)` Nearest Neighbors to `\(x\)` using distance
  + Euclidean Distance: `\(d(p,q) = \sqrt{\sum^n_{i=1}(p_i - q_i)^2}\)`
- Among the `\(k\)` nearest neighbors, count the number of data points in each category (or find the conditional probability the new point `\((x_0)\)` is in category *j*).
  + `\(P(Y=j|X=x_0) = \frac{1}{k}\sum_{i \in N_0}I(y_i = j)\)`
- Assign the new data point to a category, where you counted the most neighbors/highest probability from formula above.

---
## KNN for Classification Steps

&lt;img src="./images/knn-pic.png" width="75%" style="display: block; margin: auto;" /&gt;

---
## `knn()`

__Example__: Let's classify our new points using `\(k=2\)`.


``` r
library(class)
knnModel = knn(train = data[,1:2], 
               test = new.points[,1:2], 
               cl = data$group, 
               k = 2, prob = TRUE)
knnModel
```

```
## [1] A C
## attr(,"prob")
## [1] 1 1
## Levels: A B C
```

---
## `knn()`

What if we use more points, `\(k=10\)`?


``` r
knnModel = knn(train = data[,1:2], 
               test = new.points[,1:2], 
               cl = data$group, 
               k = 10, prob = TRUE)
knnModel
```

```
## [1] A C
## attr(,"prob")
## [1] 0.7 0.8
## Levels: A B C
```

---
## Advantages and disadvantages of `\(k\)`-nearest neighbors

- The algorithm is easy to implement and straight forward. 

- Sometimes it is hard to decide the `\(k\)` value.
  + With more variables included, the accuracy will be affected.
  + Sensitive to outliers
  + may require scaling data
- To provide accurate classification, KNN requires a lot of observations relative to the number of predictors—that is, `\(n\)` much larger than `\(p\)`.

- Since using Euclidean distance, can only use quantitative predictors

---
## Choice of k

&lt;img src="./images/choose-k.png" width="75%" style="display: block; margin: auto;" /&gt;

+ *k* = 1: low bias, but high variance
+ *k* = 100: low variance, but high bias

---
## Choice of k

&lt;img src="./images/error-change-k.png" width="95%" style="display: block; margin: auto;" /&gt;


---
## Example: Credit Utilization

__Example__: Can we use KNN to predict which utilization quantile a new customer falls into based on their application data?


``` r
library(ISLR)
data(Credit)

Credit &lt;- Credit %&gt;% mutate(Utilization = Balance/Limit) %&gt;% 
  mutate(Quartile = ifelse(Utilization&lt;0.01851, 'Q1', 
                           ifelse(Utilization&lt;0.09873, 'Q2',
                           ifelse(Utilization&lt;0.14325, 'Q3',
                                  'Q4'))))
```

---
## Example: Credit Utilization

We want to predict the utilization quantile based on two application characteristics: credit rating and age.

&lt;img src="knn-and-classification_files/figure-html/unnamed-chunk-12-1.png" style="display: block; margin: auto;" /&gt;

---
### Example: Credit Utilization

New applicants:

Name|Age|Credit Rating
---|---|---
Lacey|33|750
Zach|47|400
Ashlee|21|250




Plotting the new applicants. Use `fct_relevel()` to reorder the categories.




&lt;img src="knn-and-classification_files/figure-html/unnamed-chunk-15-1.png" style="display: block; margin: auto;" /&gt;

---
## Example: Credit Utilization

Fit a first model with `\(k=10\)`.


``` r
knn10 = knn(train = old[,1:2],
            test = applicants[,1:2],
            cl = old[,3], 
            k = 10, prob = TRUE)
knn10
```

```
## [1] Q3 Q4 Q2
## attr(,"prob")
## [1] 0.7 0.4 0.8
## Levels: Q1 Q2 Q3 Q4
```

---
## Example: Credit Utilization

What if we use `\(k=20\)`?


``` r
knn20 = knn(train = old[,1:2],
            test = applicants[,1:2],
            cl = old[,3], 
            k = 20, prob = TRUE)
knn20
```

```
## [1] Q3 Q4 Q2
## attr(,"prob")
## [1] 0.65 0.40 0.65
## Levels: Q1 Q2 Q3 Q4
```

---
## Example: Credit Utilization
Going bigger: `\(k=100\)`


``` r
knn100 = knn(train = old[,1:2],
            test = applicants[,1:2],
            cl = old[,3], 
            k = 100, prob = TRUE)
knn100
```

```
## [1] Q4 Q4 Q2
## attr(,"prob")
## [1] 0.44 0.46 0.45
## Levels: Q1 Q2 Q3 Q4
```

---
## Evaluate Prediction Accuracy

__Example__: Let's add some more dimensions to the model. We want to know if k-nearest neighbor is effective at predicting quartile membership using an applicant's age, credit rating, income, number of existing credit cards, and education level. I'll randomly select 100 observations for testing, and assign the other 300 to my training data set.


``` r
set.seed(365)
test_ID = sample(1:nrow(Credit), size = 100)
TEST = Credit[test_ID,]
TRAIN = Credit[-test_ID, ]
```

---
## Evaluate models 

Now, we'll set the testing data as "new data", and make predictions using the k-nearest neighbors from the training data.


``` r
knn_train = TRAIN %&gt;% dplyr::select(Age, Rating, Income, Cards, Education)
knn_test = TEST %&gt;% dplyr::select(Age, Rating, Income, Cards, Education) 

knn50 = knn(train = knn_train, 
            test = knn_test,
            cl = TRAIN$Quartile, 
            k = 50, prob = TRUE)
knn50
```

```
##   [1] Q4 Q1 Q4 Q1 Q4 Q3 Q4 Q4 Q1 Q4 Q2 Q2 Q4 Q4 Q3 Q1 Q1 Q3 Q4 Q1 Q4 Q2 Q3 Q2 Q2
##  [26] Q4 Q3 Q4 Q4 Q2 Q2 Q2 Q3 Q2 Q1 Q4 Q4 Q3 Q3 Q2 Q1 Q2 Q3 Q4 Q1 Q4 Q3 Q2 Q4 Q4
##  [51] Q4 Q2 Q4 Q1 Q4 Q1 Q1 Q2 Q1 Q1 Q1 Q4 Q1 Q4 Q4 Q1 Q4 Q4 Q4 Q4 Q2 Q1 Q4 Q2 Q3
##  [76] Q2 Q2 Q1 Q1 Q4 Q2 Q4 Q2 Q3 Q2 Q4 Q1 Q4 Q4 Q2 Q4 Q4 Q4 Q4 Q2 Q2 Q4 Q2 Q1 Q2
## attr(,"prob")
##   [1] 0.66 0.86 0.54 0.96 0.50 0.40 0.36 0.52 0.96 0.66 0.54 0.56 0.54 0.42 0.38
##  [16] 0.96 0.92 0.42 0.46 0.98 0.44 0.52 0.40 0.54 0.60 0.46 0.46 0.42 0.62 0.52
##  [31] 0.52 0.56 0.40 0.54 0.58 0.46 0.52 0.38 0.46 0.52 0.96 0.44 0.44 0.42 0.98
##  [46] 0.50 0.44 0.48 0.54 0.46 0.50 0.58 0.46 0.90 0.50 0.94 0.96 0.42 0.96 0.82
##  [61] 0.54 0.48 0.54 0.58 0.44 0.96 0.44 0.46 0.58 0.54 0.34 0.96 0.44 0.58 0.42
##  [76] 0.34 0.54 0.96 0.96 0.42 0.60 0.52 0.56 0.40 0.48 0.54 0.64 0.34 0.60 0.56
##  [91] 0.44 0.50 0.48 0.50 0.46 0.52 0.44 0.58 0.78 0.58
## Levels: Q1 Q2 Q3 Q4
```

---
## Evaluate models 

Now, we'll set the testing data as "new data", and make predictions using the k-nearest neighbors from the training data.


``` r
#Create Confusion Matrix
t = table(knn50, TEST$Quartile)
t
```

```
##      
## knn50 Q1 Q2 Q3 Q4
##    Q1 18  2  1  1
##    Q2  4 16  5  1
##    Q3  0  3  7  2
##    Q4  0  8 16 16
```

``` r
sum(diag(t))/nrow(TEST) #Classification Accuracy
```

```
## [1] 0.57
```

---
## Scaling Data

Prevents features with larger magnitudes from dominating the distance calculation (not always necessary)


``` r
knn_train_scale &lt;- knn_train %&gt;% scale()
knn_test_scale &lt;- knn_test %&gt;% scale()

knn50_scale = knn(train = knn_train_scale, 
            test = knn_test_scale,
            cl = TRAIN$Quartile, 
            k = 50, prob = TRUE)


t_scale = table(knn50_scale, TEST$Quartile)

sum(diag(t_scale))/nrow(TEST) #Classification Accuracy
```

```
## [1] 0.44
```

---
### KNN for Regression 

Can also use KNN to predict a quantiative response (alternative to Linear Regression)

In the KNN algorithm, `\(k\)` specifies the number of neighbors and its algorithm is as follows:

- Choose the number `\(k\)` of neighbors
- Find the `\(k\)` Nearest Neighbor of an unknown data point using distance.
  + Euclidean Distance: `\(d(p,q) = \sqrt{\sum^n_{i=1}(p_i - q_i)^2}\)`
- Estimates `\(f(x_0)\)` (response value of the new observation) using the average of all the training responses of the `\(k\)` Nearest Neighbors
  + `\(\hat{f}(x_0) = \frac{1}{K}\sum_{x_i \in N_0}y_i\)`

---
## Example: Credit Utilization



``` r
knn_train = TRAIN %&gt;% dplyr::select(Age, Rating, Income, Cards, 
                                    Education)
knn_test = TEST %&gt;% dplyr::select(Age, Rating, Income, Cards, 
                                  Education) 

knn50 = FNN::knn.reg(train = knn_train, 
            test = knn_test,
            y = TRAIN$Utilization, 
            k = 50)

head(knn50$pred, n = 5)
```

```
## [1] 0.157343839 0.011478125 0.144051032 0.005360386 0.142495141
```

``` r
rmse(TEST$Utilization, knn50$pred)
```

```
## [1] 0.0386645
```

---
## Linear Regression vs KNN Regression

**In General**: 

.center[
Parametric approaches will outperform nonparametric approaches if the parametric form that has been selected is close to the true form of the data
]

&lt;br&gt;

So in situations where the relationship is nonlinear, KNN regression may perform better than Linear Regression

- But, Linear Regression may actually perform better than KNN as the number of variables (dimensions) increase
  + Curse of dimensionality

  
---
## Try by yourself

1. Let's see whether we can predict people's ethnicity based on their credit card information (Age, Rating, Income, Cards, Education, Balance). Try to fit a KNN model with K = 5, 10, 25, 50, 100. See how the prediction values change and think about why. Write a function/loop to help

2. Run a multiple linear regression model on the same data, and compare the RMSE with the KNN regression model. Which method is performing better? Will increasing/decreasing *k* lower the RMSE?

---
## Summary 

Linear model: The basic model for regression, easy for interpretation, but has strict assumption thus hard to get a better prediction

Decision tree: Can be applied to regression and classification. Has good data visualization but it has high variance. 

Random Forest: a collection of tree models. Hard for interpretation but it can output variable importance. Can be useful if you have a lot of variable and what want to select the most useful ones. Also, if you have variables are not independent with each other, it performs better than the linear model. 

KNN：Can be applied to regression and classification. relatively fast, no assumption need and add data anytime. May affect the accuracy if we have too many variables and need to use CV to decide the k value. 
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
